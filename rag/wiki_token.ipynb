{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Wiki doc json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/wikipedia_documents.json') as f:\n",
    "    wiki = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_model = 'gogamza/kobart-base-v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_wiki_passages = [doc['text'] for doc in wiki.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60613"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_wiki_passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56737"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_wiki_passages = list(set(total_wiki_passages))\n",
    "len(unique_wiki_passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_wiki_json\n",
    "unique_wiki_dict = {idx: passage for idx, passage in enumerate(unique_wiki_passages)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "with open('unique_wiki_passages.json', 'w') as f:\n",
    "    json.dump(unique_wiki_dict, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # passage를 \\n\\n 간격으로하여 하나의 txt 파일로 저장\n",
    "# with open('unique_wiki_passages.txt', 'w') as f:\n",
    "#     f.write('\\n\\n'.join(unique_wiki_passages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load\n",
    "# with open('unique_wiki_passages.json') as f:\n",
    "#     unique_wiki_dict_sample = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    56737.000000\n",
       "mean       750.820593\n",
       "std        698.576330\n",
       "min        184.000000\n",
       "25%        416.000000\n",
       "50%        578.000000\n",
       "75%        856.000000\n",
       "max      46099.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 간단 길이 분포 확인\n",
    "import pandas as pd\n",
    "s = pd.Series(unique_wiki_passages)\n",
    "s.str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain을 활용해 tiktoken(OpenAI의 fast BPE tokenizer)로 chunk 분리\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # character의 개수 단위 분리\n",
    "\n",
    "chunk_size = 300\n",
    "chunk_overlap = 50\n",
    "with open(\"./unique_wiki_passages.txt\") as f:\n",
    "    total_wiki = f.read()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    ")\n",
    "texts = text_splitter.split_text(total_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384363"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1623년 3월 13일 반정이 성공하고 광해군이 인목대비의 폐위교서 발표 후 인조가 즉위하였으며, 주변에서 호위하였다. 인조 즉위 직후 광해군 폐출과 정변을 지원한 공로로 분충찬모입기명륜정사공신(奮忠贊謨立紀明倫靖社功臣) 1등에 녹훈되고, 이후',\n",
       " '1등에 녹훈되고, 이후 호조판서에 승진되고 완풍군(完豊君)에 봉군되었다. 호조판서가 되어서는 호조의 사무가 매우 많고 어지러웠으나, 엄하게 다스리고 해결하니 교활한 아전이 잔머리를 굴리지 못하였다.',\n",
       " '1624년(인조 2) 경기도관찰사(京畿道觀察使)가 되었다가 1624년(인조 2) 논공행상에 불만을 품은 이괄(李适), 한명련 등이 거병을 일으켜, 반란이 발생하자 원수부 부원수(副元帥)로서 출정, 이괄군과 교전하였다. 그러나 개성까지 이괄군을 추격했지만 여건이 되지',\n",
       " '이괄군을 추격했지만 여건이 되지 않아 더 나가지 못하고 지체했는데, 오히려 밤에 이괄군의 기습을 당하기도 했다. 더 나가지 못해, 반란군을 추격하다가 중간에 멈춘 죄로 파직되었다.',\n",
       " '곧 인조의 명으로 백의종군의 명이 내려졌으나 얼마 뒤 인조가 특별히 용서하여 다시 서용되고, 완풍군에 봉해졌다. 같은 해 어영대장(御營大將)이 되어 수어사(守禦使)를 겸하였고, 그 해 한성과 경기도의 군사 지휘를 목적으로 사직동(社稷洞) 북쪽에 총융청이',\n",
       " '사직동(社稷洞) 북쪽에 총융청이 설치되자, 겸 총융청사(摠戎廳使)가 되어 남양(南陽), 수원부, 장단군 등 3진(鎭)의 지휘와 동원권을 행사하였다.',\n",
       " '이때 대신 경기도는 나라의 인후(咽喉, 코)와 같아서 군사가 정예하지 못하면 위급한 시기를 당하여 득력(得力)하기 어렵다며 그를 총융사로 추천, 겸직하게 하였다. 동시에 훈련원의 교련(敎鍊)도 같이 맡아보았다. 이때 군율을 엄하게 정하고, 장교를',\n",
       " '이때 군율을 엄하게 정하고, 장교를 선발하여 수시로 군사훈련을 시키고, 봄가을로 크게 사열하여 상벌을 주었다. 또한 둔전(屯田)을 설치하고, 군량미를 저축하여 병농(兵農)이 서로 침탈하지 않게 하였다. 경기도 지역 주민들이 처음에는 괴로워하더니 뒤에는',\n",
       " \"주민들이 처음에는 괴로워하더니 뒤에는 덕을 칭송하였다 한다. 이때 그가 남한산성을 답사하고 인조에게 건의하여 '백제 시대에 남한(南漢)에 도읍을 세우고 지키어 적이 감히 엿보지 못하였으니 참으로 형승지(形勝地)입니다. 청하건대 이곳에 성을 쌓아\",\n",
       " \"청하건대 이곳에 성을 쌓아 경도(京都)의 방패가 되게 하소서.' 하였다. 그의 사유가 받아들여져 임금이 이귀(李貴) 등에게 답사를 명했고, 이귀 등이 그의 건의가 모두 옳다고 하였다.\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to dict\n",
    "texts_dict = {idx: passage for idx, passage in enumerate(texts)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "with open('unique_wiki_passages_chunked.json', 'w') as f:\n",
    "    json.dump(texts_dict, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
